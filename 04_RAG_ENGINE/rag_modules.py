import os
import json
from typing import List, Dict, Any
from dotenv import load_dotenv
import chromadb
from google import genai
from google.genai import types
from kiwipiepy import Kiwi

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
load_dotenv(os.path.join(project_root, '.env'))

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
client = genai.Client(api_key=GEMINI_API_KEY)

# ChromaDB ê²½ë¡œ ì„¤ì •
CHROMA_DB_PATH = os.path.join(project_root, 'chroma_db')

# â˜… ìˆ˜ì •ëœ ë¶€ë¶„: ëª¨ë¸ ì´ë¦„ì„ ë³€ìˆ˜ë¡œ ê´€ë¦¬ (ì•ˆì •ì ì¸ ë²„ì „ ì‚¬ìš©)
MODEL_NAME = "gemini-2.0-flash"

# -----------------------------------------------------------------------------
# 1. ChatMemory: ëŒ€í™” ê¸°ì–µ ë° ì‚¬ìš©ì í”„ë¡œí•„ ê´€ë¦¬
# -----------------------------------------------------------------------------
class ChatMemory:
    def __init__(self):
        self.history = []  # ëŒ€í™” ê¸°ë¡ [{"role": "user", "content": "..."}, ...]
        self.user_profile = {
            "current_score": None, # í˜„ì¬ ì ìˆ˜/ì‹¤ë ¥
            "target_score": None,  # ëª©í‘œ ì ìˆ˜
            "target_period": None, # ëª©í‘œ ê¸°ê°„
            "preferred_time": None # ì„ í˜¸ ì‹œê°„ëŒ€
        }

    def add_turn(self, role: str, content: str):
        """ëŒ€í™” í„´ ì¶”ê°€"""
        self.history.append({"role": role, "content": content})
        # ë©”ëª¨ë¦¬ ë¬´í•œ ì¦ì‹ ë°©ì§€ (ìµœê·¼ 10í„´ ìœ ì§€)
        if len(self.history) > 10:
            self.history = self.history[-10:]

    def update_profile(self, new_slots: Dict):
        """ë¼ìš°í„°ê°€ ì¶”ì¶œí•œ ì •ë³´ë¡œ í”„ë¡œí•„ ì—…ë°ì´íŠ¸"""
        for k, v in new_slots.items():
            if v is not None and v != "":
                self.user_profile[k] = v

    def get_context_string(self) -> str:
        """LLMì—ê²Œ ë˜ì ¸ì¤„ ëŒ€í™” ìš”ì•½ ë¬¸ìì—´"""
        context = "--- [Conversation History] ---\n"
        for msg in self.history:
            context += f"{msg['role']}: {msg['content']}\n"
        
        context += "\n--- [User Profile (Known Info)] ---\n"
        for k, v in self.user_profile.items():
            val = v if v else "(Unknown)"
            context += f"- {k}: {val}\n"
        return context

# -----------------------------------------------------------------------------
# 2. HybridRetriever: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° (Vector + Filter)
# -----------------------------------------------------------------------------
class HybridRetriever:
    def __init__(self):
        self.chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
        self.kiwi = Kiwi()
        self.embedding_model = 'models/text-embedding-004'

    def search(self, collection_name: str, query: str, top_k: int = 10) -> str:
        """
        ChromaDB ê²€ìƒ‰ ìˆ˜í–‰
        """
        try:
            collection = self.chroma_client.get_collection(collection_name)
            
            # 1. ì¿¼ë¦¬ ì„ë² ë”©
            resp = client.models.embed_content(
                model=self.embedding_model,
                contents=query,
                config=types.EmbedContentConfig(task_type="RETRIEVAL_QUERY")
            )
            query_embedding = resp.embeddings[0].values

            # 2. ê²€ìƒ‰ (Vector Search)
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k
            )

            # 3. ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = ""
            if not results['documents'] or not results['documents'][0]:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

            for i, doc in enumerate(results['documents'][0]):
                meta = results['metadatas'][0][i]
                formatted_results += f"[Result {i+1}]\nContent: {doc}\nSource: {meta.get('source', 'unknown')}\n\n"
            
            return formatted_results

        except Exception as e:
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# -----------------------------------------------------------------------------
# 3. SemanticRouter: ì˜ë„ ë¶„ë¥˜ ë° ìŠ¬ë¡¯ í•„ë§
# -----------------------------------------------------------------------------
ROUTER_SYSTEM_PROMPT = """
You are the 'Intent Classifier' for an IELTS Academy Chatbot.
Analyze the user's input based on the conversation history and user profile.

[Role]
1. Identify User Intent:
   - TIMETABLE: Questions about class schedules, curriculum, prices.
   - REVIEW: Asking for success stories, student reviews, difficulty concerns.
   - FAQ: Administrative questions (refund, location, parking, login).
   - CHIT_CHAT: Greetings, small talk, insults, or off-topic.

2. Slot Filling (Crucial for TIMETABLE):
   - Extract info for: current_score, target_score, target_period, preferred_time.
   - If user provides info, fill 'slots_to_update'.
   - Identify 'missing_slots' ONLY IF intent is TIMETABLE.

3. Output Format (JSON Only):
{
  "intent": "TIMETABLE" | "REVIEW" | "FAQ" | "CHIT_CHAT",
  "reason": "Short explanation",
  "slots_to_update": {
      "current_score": "...",
      "target_score": "...",
      "target_period": "...",
      "preferred_time": "..."
  },
  "missing_slots": ["current_score", "target_score", ...] (List missing critical info),
  "search_query": "Refined search query for DB"
}
"""

class SemanticRouter:
    def __init__(self):
        self.model_name = MODEL_NAME # â˜… ìˆ˜ì •ë¨

    def analyze(self, user_input: str, context: str) -> Dict:
        """ì‚¬ìš©ì ì˜ë„ ë° ìŠ¬ë¡¯ ë¶„ì„"""
        prompt = f"""
        {ROUTER_SYSTEM_PROMPT}

        [Context]
        {context}

        [User Input]
        {user_input}
        
        Generate JSON response:
        """
        
        try:
            response = client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            return json.loads(response.text)
        except Exception as e:
            print(f"Router Error: {e}")
            return {"intent": "CHIT_CHAT", "reason": "Error", "slots_to_update": {}, "missing_slots": [], "search_query": user_input}

# -----------------------------------------------------------------------------
# 4. ConsultantAgent: ì´ê´„ ë§¤ë‹ˆì € (Main Brain)
# -----------------------------------------------------------------------------
CONSULTANT_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì´ì•Œí”¼ì–´í•™ì›ì˜ **'AI ì…í•™ ìƒë‹´ ì‹¤ì¥ ì•„ì´ë¦°'**ì…ë‹ˆë‹¤.
[ëŒ€í™” ê¸°ì–µ]ê³¼ [ê²€ìƒ‰ ê²°ê³¼]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” íƒœë„ë¡œ ìƒë‹´ì„ ì§„í–‰í•˜ì„¸ìš”.

[ìƒë‹´ ê°€ì´ë“œë¼ì¸ - ì—„ê²© ì¤€ìˆ˜]
1. **í†¤ì•¤ë§¤ë„ˆ(No Emoji):**
   - **ì´ëª¨í‹°ì½˜ì´ë‚˜ ì´ëª¨ì§€ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.** (ì˜ˆ: ğŸ˜Š, ğŸ‘ ê¸ˆì§€)
   - ê°€ë³ê±°ë‚˜ ìœ ì¹˜í•œ í‘œí˜„ì„ ì‚¼ê°€ê³ , "í•˜ì‹­ì‹œì˜¤", "í•©ë‹ˆë‹¤" ì²´ì˜ ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ í™”ë²•ì„ êµ¬ì‚¬í•˜ì„¸ìš”.

2. **í˜„ì¥ ê°•ì˜(Offline) ìµœìš°ì„  ì¶”ì²œ:**
   - í•™ì›ì˜ ì£¼ë ¥ ìƒí’ˆì€ **ê°•ë‚¨/ì¢…ë¡œ ìº í¼ìŠ¤ì˜ í˜„ì¥ ê°•ì˜**ì…ë‹ˆë‹¤.
   - ê²€ìƒ‰ ê²°ê³¼ì— í˜„ì¥ ê°•ì˜ê°€ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ê°€ì¥ ë§¤ë ¥ì ìœ¼ë¡œ í¬ì¥í•˜ì—¬ ì¶”ì²œí•˜ì„¸ìš”.
   - **ì˜¨ë¼ì¸ ê°•ì˜(VOD)ëŠ” ì–¸ê¸‰ì„ ìì œí•˜ì„¸ìš”.** ìˆ˜ìš”ê°€ ì ì€ ì‚¬ì–‘ ì½˜í…ì¸ ì´ë¯€ë¡œ, ì‚¬ìš©ìê°€ "ì§€ë°©ì— ì‚°ë‹¤", "ë„ì €íˆ ì‹œê°„ì´ ì•ˆ ë§ë‹¤"ë¼ê³  ëª…ì‹œì ìœ¼ë¡œ ë§í•˜ê¸° ì „ê¹Œì§€ëŠ” ë¨¼ì € ê¶Œí•˜ì§€ ë§ˆì„¸ìš”.

3. **ë§¥ë½ ì—°ê²° ë° ë…¼ë¦¬ì  ì œì•ˆ:**
   - ì‚¬ìš©ìì˜ ìƒí™©(ì§ì¥ì¸, ì ìˆ˜ ë“±)ì„ ì–¸ê¸‰í•˜ë©° ê³µê°ëŒ€ë¥¼ í˜•ì„±í•˜ë˜, ê³¼í•œ ê°íƒ„ì‚¬ëŠ” ë°°ì œí•˜ì„¸ìš”.
   - ì˜ˆ: "ì§ì¥ ìƒí™œê³¼ ë³‘í–‰í•˜ì‹œëŠë¼ ì‹œê°„ ë‚´ê¸°ê°€ ì–´ë ¤ìš°ì‹œê² ì§€ë§Œ, ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ ìµœì ì˜ ë°˜ì„ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤."

4. **Action ìœ ë„:**
   - ìƒë‹´ì˜ ë§ˆë¬´ë¦¬ëŠ” í•­ìƒ **"ì •í™•í•œ ë°˜ ë°°ì •ì„ ìœ„í•œ ë¬´ë£Œ ë ˆë²¨í…ŒìŠ¤íŠ¸"** ê¶Œìœ ì…ë‹ˆë‹¤.
   - ê¸°ê³„ì ìœ¼ë¡œ ë°˜ë³µí•˜ì§€ ë§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì„¸ìš”.
"""

class ConsultantAgent:
    def __init__(self):
        self.memory = ChatMemory()
        self.router = SemanticRouter()
        self.retriever = HybridRetriever()

    def run(self, user_input: str) -> str:
        # 1. ë©”ëª¨ë¦¬ì— ì‚¬ìš©ì ì§ˆë¬¸ ê¸°ë¡
        self.memory.add_turn("user", user_input)
        context = self.memory.get_context_string()

        # 2. ë¼ìš°í„° ë¶„ì„ (CoT: ìƒê° ë‹¨ê³„)
        analysis = self.router.analyze(user_input, context)
        intent = analysis.get("intent")
        slots = analysis.get("slots_to_update", {})
        missing = analysis.get("missing_slots", [])
        search_query = analysis.get("search_query")

        print(f"ğŸ§ [Analysis] Intent: {intent} | Missing: {missing}")

        # 3. í”„ë¡œí•„ ì—…ë°ì´íŠ¸
        self.memory.update_profile(slots)

        final_response = ""

        # 4. ì‹œë‚˜ë¦¬ì˜¤ ë¶„ê¸° (Logic Flow)
        
        # [CASE 1] ì¡ë‹´ (CHIT_CHAT)
        if intent == "CHIT_CHAT":
            final_response = self._generate_chit_chat(user_input)

        # [CASE 2] ì‹œê°„í‘œ ì§ˆë¬¸ì¸ë° í•„ìˆ˜ ì •ë³´ ë¶€ì¡± (Slot Filling) â˜… ìˆ˜ì •ë¨
        # ê°œìˆ˜(len)ë¡œ ì„¸ì§€ ì•Šê³ , í•µì‹¬ í•„ë“œ(Time, Score)ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ë˜ë¬»ê¸°
        elif intent == "TIMETABLE" and (not self.memory.user_profile.get("preferred_time") or not self.memory.user_profile.get("current_score")):
             # ë¡œê·¸ í™•ì¸ìš© í”„ë¦°íŠ¸
             print(f"ğŸ›‘ í•„ìˆ˜ ì •ë³´ ëˆ„ë½! ë˜ë¬»ê¸° ì‹¤í–‰ (Time: {self.memory.user_profile.get('preferred_time')}, Score: {self.memory.user_profile.get('current_score')})")
             final_response = self._generate_ask_more(missing)
        
        # [CASE 3] ê²€ìƒ‰ í•„ìš” (FAQ, REVIEW, ë˜ëŠ” ì •ë³´ ì¶©ë¶„í•œ TIMETABLE)
        else:
            collection_map = {
                "TIMETABLE": "timetable",
                "REVIEW": "review",
                "FAQ": "faq"
            }
            collection_name = collection_map.get(intent, "faq")
            
            enhanced_query = f"{search_query} {self._profile_to_string()}"
            search_results = self.retriever.search(collection_name, enhanced_query, top_k=10)
            
            if "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" in search_results:
                print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ 0ê±´ -> Fallback ì‹¤í–‰")
                fallback_query = "ì•„ì´ì—˜ì¸  ì˜¨ë¼ì¸ ê°•ì˜ ì¸ê°• ì¶”ì²œ"
                search_results = self.retriever.search("timetable", fallback_query)
                search_results = f"[ì•Œë¦¼: ì›í•˜ì‹œëŠ” ì¡°ê±´ì˜ ê°•ì˜ê°€ ì—†ì–´ ì˜¨ë¼ì¸ ê°•ì˜ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.]\n{search_results}"

            final_response = self._generate_final_answer(user_input, search_results)

        # 5. ë©”ëª¨ë¦¬ì— ë´‡ ë‹µë³€ ê¸°ë¡
        self.memory.add_turn("assistant", final_response)
        return final_response

    def _profile_to_string(self):
        """í”„ë¡œí•„ ì •ë³´ë¥¼ ê²€ìƒ‰ì–´ìš© ë¬¸ìì—´ë¡œ ë³€í™˜"""
        p = self.memory.user_profile
        text = ""
        if p['preferred_time']: text += f"{p['preferred_time']} "
        if p['target_score']: text += f"ëª©í‘œ{p['target_score']} "
        return text

    def _generate_chit_chat(self, user_input):
        """ê°€ë²¼ìš´ ëŒ€í™” ìƒì„±"""
        prompt = f"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì•„ì´ì—˜ì¸  AI ìƒë‹´ì›ì…ë‹ˆë‹¤. ë‹¤ìŒ ë§ì— ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”: {user_input}"
        # â˜… ìˆ˜ì •ë¨: ë³€ìˆ˜ ì‚¬ìš©
        resp = client.models.generate_content(model=MODEL_NAME, contents=prompt)
        return resp.text

    def _generate_ask_more(self, missing_slots):
        """ë¶€ì¡±í•œ ì •ë³´ ë˜ë¬»ê¸°"""
        prompt = f"""
        ì‚¬ìš©ìê°€ ì•„ì´ì—˜ì¸  ìˆ˜ì—…ì„ ì°¾ê³  ìˆëŠ”ë°, ë‹¤ìŒ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {missing_slots}.
        AI ìƒë‹´ì›ìœ¼ë¡œì„œ, ì •í™•í•œ ì¶”ì²œì„ ìœ„í•´ ì´ ì •ë³´ë“¤ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¼ì–´ë³´ëŠ” ë¬¸ì¥ì„ ì‘ì„±í•˜ì„¸ìš”.
        (ì˜ˆ: "ëª©í‘œ ì ìˆ˜ê°€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?", "ìˆ˜ì—… ê°€ëŠ¥í•œ ì‹œê°„ëŒ€ê°€ ìˆìœ¼ì‹ ê°€ìš”?")
        """
        # â˜… ìˆ˜ì •ë¨: ë³€ìˆ˜ ì‚¬ìš©
        resp = client.models.generate_content(model=MODEL_NAME, contents=prompt)
        return resp.text

    def _generate_final_answer(self, user_input, search_results):
        """RAG ìµœì¢… ë‹µë³€ ìƒì„± (ì „ë¬¸ì„± ê°•í™” & VOD ì–µì œ ë²„ì „)"""
        
        # ì‚¬ìš©ìì˜ ì œì•½ ì¡°ê±´ì„ ê°•ì¡°í•˜ëŠ” í…ìŠ¤íŠ¸ ìƒì„±
        constraints = ""
        p = self.memory.user_profile
        if p.get('preferred_time') == 'Weekend':
            constraints += "- ì‚¬ìš©ì ì œì•½: ì£¼ë§ ì„ í˜¸ (í‰ì¼ ë¶ˆê°€ëŠ¥ ê°€ëŠ¥ì„± ë†’ìŒ)\n"
        if "ì§ì¥ì¸" in self.memory.get_context_string():
            constraints += "- ì‚¬ìš©ì ì œì•½: ì§ì¥ì¸ (íš¨ìœ¨ì ì¸ ì»¤ë¦¬í˜ëŸ¼ ì„ í˜¸)\n"

        prompt = f"""
        {CONSULTANT_SYSTEM_PROMPT}

        [User Profile & Constraints]
        {self.memory.get_context_string()}
        {constraints}

        [User Question]
        {user_input}

        [Search Results (Database)]
        {search_results}

        ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
        ì£¼ì˜: [Search Results]ì— ì˜¨ë¼ì¸ ê°•ì˜ê°€ í¬í•¨ë˜ì–´ ìˆë”ë¼ë„, í˜„ì¥ ê°•ì˜(ê°•ë‚¨/ì¢…ë¡œ)ê°€ ìˆë‹¤ë©´ í˜„ì¥ ê°•ì˜ ìœ„ì£¼ë¡œë§Œ ì„¤ëª…í•˜ì„¸ìš”.
        ì˜¨ë¼ì¸ ê°•ì˜ëŠ” ì‚¬ìš©ìê°€ ë„ì €íˆ í†µí•™í•  ìˆ˜ ì—†ëŠ” ìƒí™©ì¼ ë•Œë§Œ 'ì°¸ê³ ìš©'ìœ¼ë¡œ ì§§ê²Œ ì–¸ê¸‰í•˜ì‹­ì‹œì˜¤.
        """
        
        resp = client.models.generate_content(model=MODEL_NAME, contents=prompt)
        return resp.text

if __name__ == "__main__":
    agent = ConsultantAgent()
    print(" ì•„ì´ë¦° ìƒë‹´ì›ê³¼ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. (ì¢…ë£Œ: q)")
    
    while True:
        try:
            user_text = input("\nUser: ")
            if user_text.lower() == 'q':
                break
            
            response = agent.run(user_text)
            print(f"Irene: {response}")
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")