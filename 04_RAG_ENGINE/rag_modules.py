import os
import json
from typing import List, Dict, Any
from dotenv import load_dotenv
import chromadb
from google import genai
from google.genai import types
from kiwipiepy import Kiwi
from langchain.schema import SystemMessage, HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI


current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
load_dotenv(os.path.join(project_root, '.env'))

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
client = genai.Client(api_key=GEMINI_API_KEY)


CHROMA_DB_PATH = os.path.join(project_root, 'chroma_db')

MODEL_NAME = "gemini-2.0-flash"




class ChatMemory:
    def __init__(self):
        self.history = []  
        self.user_profile = {
            "current_score": None, 
            "target_score": None,  
            "target_period": None, 
            "preferred_time": None 
        }

    def add_turn(self, role: str, content: str):
        self.history.append({"role": role, "content": content})
        if len(self.history) > 10:
            self.history = self.history[-10:]

    def update_profile(self, new_slots: Dict):
        for k, v in new_slots.items():
            if v is not None and v != "":
                self.user_profile[k] = v

    def get_context_string(self) -> str:
        context = "--- [Conversation History] ---\n"
        for msg in self.history:
            context += f"{msg['role']}: {msg['content']}\n"
        
        context += "\n--- [User Profile (Known Info)] ---\n"
        for k, v in self.user_profile.items():
            val = v if v else "(Unknown)"
            context += f"- {k}: {val}\n"
        return context




class HybridRetriever:
    def __init__(self):
        self.chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
        self.kiwi = Kiwi()
        self.embedding_model = 'models/text-embedding-004'

    def search(self, collection_name: str, query: str, top_k: int = 10) -> str:
        try:
            collection = self.chroma_client.get_collection(collection_name)
            
            resp = client.models.embed_content(
                model=self.embedding_model,
                contents=query,
                config=types.EmbedContentConfig(task_type="RETRIEVAL_QUERY")
            )
            query_embedding = resp.embeddings[0].values

            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k
            )

            formatted_results = ""
            if not results['documents'] or not results['documents'][0]:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

            for i, doc in enumerate(results['documents'][0]):
                meta = results['metadatas'][0][i]
                formatted_results += f"[Result {i+1}]\nContent: {doc}\nSource: {meta.get('source', 'unknown')}\n\n"
            
            return formatted_results

        except Exception as e:
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"




ROUTER_SYSTEM_PROMPT = """
You are the 'Intent Classifier' for an IELTS Academy Chatbot.
Analyze the user's input based on the conversation history and user profile.

[Role]
1. Identify User Intent:
   - TIMETABLE: Questions about class schedules, curriculum, prices.
   - REVIEW: Asking for success stories, student reviews, difficulty concerns.
   - FAQ: Administrative questions (refund, location, parking, login).
   - CHIT_CHAT: Greetings, small talk, insults, or off-topic.

2. Slot Filling (Crucial for TIMETABLE):
   - Extract info for: current_score, target_score, target_period, preferred_time.
   - If user provides info, fill 'slots_to_update'.
   - Identify 'missing_slots' ONLY IF intent is TIMETABLE.

3. Output Format (JSON Only):
{
  "intent": "TIMETABLE" | "REVIEW" | "FAQ" | "CHIT_CHAT",
  "reason": "Short explanation",
  "slots_to_update": {
      "current_score": "...",
      "target_score": "...",
      "target_period": "...",
      "preferred_time": "..."
  },
  "missing_slots": ["current_score", "target_score", ...] (List missing critical info),
  "search_query": "Refined search query for DB"
}
"""

class SemanticRouter:
    def __init__(self):
        self.model_name = MODEL_NAME

    def analyze(self, user_input: str, context: str) -> Dict:
        prompt = f"""
        {ROUTER_SYSTEM_PROMPT}

        [Context]
        {context}

        [User Input]
        {user_input}
        
        Generate JSON response:
        """
        
        try:
            response = client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            return json.loads(response.text)
        except Exception as e:
            print(f"Router Error: {e}")
            return {"intent": "CHIT_CHAT", "reason": "Error", "slots_to_update": {}, "missing_slots": [], "search_query": user_input}




CONSULTANT_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì´ì•Œí”¼ì–´í•™ì›ì˜ **'AI ì…í•™ ìƒë‹´ì› ì•„ì´ë¦°(Irene)'**ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì—ê²Œ ì¸ê°„ ìƒë‹´ì›ì¸ ì²™ ì—°ê¸°í•˜ì§€ ë§ê³ , ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ ì°¾ì•„ì£¼ëŠ” **AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œì˜ ì •ì²´ì„±**ì„ ìœ ì§€í•˜ì„¸ìš”.

[í•µì‹¬ í–‰ë™ ì§€ì¹¨]
1. **AI ì •ì²´ì„± ëª…ì‹œ ë° í†¤ì•¤ë§¤ë„ˆ:**
   - **ì´ëª¨í‹°ì½˜, ì´ëª¨ì§€(ğŸ˜Š, ğŸ‘) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€.**
   - ê³¼ë„í•œ ê°ì • ì´ì…ì´ë‚˜ ì‚¬ëŒì¸ ì²™í•˜ëŠ” ì—°ê¸°ë¥¼ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
   - "í•˜ì‹­ì‹œì˜¤", "í•©ë‹ˆë‹¤" ì²´ì˜ ì •ì¤‘í•˜ê³  ê±´ì¡°í•œ ë¹„ì¦ˆë‹ˆìŠ¤ í™”ë²•ì„ êµ¬ì‚¬í•˜ì„¸ìš”.
   - ë‹µë³€ ì„œë‘ë‚˜ ë§ë¯¸ì— í•„ìš”ì‹œ "ì €ëŠ” AI ìƒë‹´ì›ìœ¼ë¡œì„œ..."ì™€ ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ê³„ì ì¸ ì‹ ë¢°ê°ì„ ì£¼ì‹­ì‹œì˜¤.

2. **í˜„ì¥ ê°•ì˜(Offline) ìµœìš°ì„  ì¶”ì²œ ì „ëµ:**
   - í•™ì›ì˜ í•µì‹¬ ìƒí’ˆì€ **ê°•ë‚¨/ì¢…ë¡œ ìº í¼ìŠ¤ í˜„ì¥ ê°•ì˜**ì…ë‹ˆë‹¤.
   - [ê²€ìƒ‰ ê²°ê³¼]ì— í˜„ì¥ ê°•ì˜ê°€ ìˆë‹¤ë©´, ê´€ë¦¬ ì‹œìŠ¤í…œê³¼ í•™ìŠµ ë¶„ìœ„ê¸°ë¥¼ ê°•ì¡°í•˜ì—¬ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì²œí•˜ì‹­ì‹œì˜¤.
   - **ì˜¨ë¼ì¸ ê°•ì˜(VOD)ëŠ” ì–¸ê¸‰ì„ ìµœì†Œí™”í•˜ì‹­ì‹œì˜¤.** ì§€ë°© ê±°ì£¼, í•´ì™¸ ê±°ì£¼ ë“± ë¬¼ë¦¬ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥í•œ ìƒí™©ì„ì´ ëª…í™•í•  ë•Œë§Œ ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ ì œì•ˆí•˜ì‹­ì‹œì˜¤.

3. **[ì¤‘ìš”] ëŒ€í™” ì£¼ì œ ì œí•œ (Guardrails):**
   - ë‹¹ì‹ ì˜ ì „ë¬¸ ë¶„ì•¼ëŠ” ì˜¤ì§ **'IELTS ì‹œí—˜'**ê³¼ **'í•™ì› ìˆ˜ê°•'**ì…ë‹ˆë‹¤.
   - ë§›ì§‘, ì—°ì• , ì£¼ì‹, ì—¬í–‰ ë“± í•™ì›ê³¼ ë¬´ê´€í•œ ì‚¬ì ì¸ ì§ˆë¬¸(Chit-chat)ì´ ë“¤ì–´ì˜¤ë©´ **ì •ë³´ ì œê³µì„ ì •ì¤‘íˆ ê±°ì ˆ**í•˜ì‹­ì‹œì˜¤.
   - **[ê³ ê¸‰ ìŠ¤í‚¬]** ê±°ì ˆì—ì„œ ëë‚´ì§€ ë§ê³ , í•´ë‹¹ ì£¼ì œë¥¼ **'IELTS ìŠ¤í”¼í‚¹ ê¸°ì¶œ ì£¼ì œ'**ë¡œ ì—°ê²°í•˜ì—¬ ìƒë‹´ìœ¼ë¡œ ë³µê·€ì‹œí‚¤ì‹­ì‹œì˜¤.
     - (ì˜ˆì‹œ: ë§›ì§‘ ì§ˆë¬¸ -> "ì €ëŠ” AIë¼ ë§›ì§‘ì€ ì•Œì§€ ëª»í•©ë‹ˆë‹¤ë§Œ, IELTS ìŠ¤í”¼í‚¹ Part 1ì—ì„œ 'Favorite Food'ëŠ” ë¹ˆì¶œ ì£¼ì œì…ë‹ˆë‹¤. ê´€ë ¨ í‘œí˜„ì„ ì•Œë ¤ë“œë¦´ê¹Œìš”?")

4. **Action ìœ ë„ (Call to Action):**
   - ëª¨ë“  ìƒë‹´ì˜ ê²°ë¡ ì€ ì‚¬ìš©ìì˜ í˜„ì¬ ì‹¤ë ¥ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ **"ë¬´ë£Œ ë ˆë²¨í…ŒìŠ¤íŠ¸"** ê¶Œìœ ë¡œ ì´ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.
   - ê¸°ê³„ì ì¸ ë°˜ë³µ ëŒ€ì‹ , ì‚¬ìš©ìì˜ ëª©í‘œ ì ìˆ˜ ë‹¬ì„±ì„ ìœ„í•œ 'í•„ìˆ˜ ì ˆì°¨'ì„ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.

[ì°¸ê³ : ê²€ìƒ‰ ê²°ê³¼(Context)]
ì•„ë˜ ì œê³µëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì‹¤ì— ì…ê°í•˜ì—¬ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
"""

class ConsultantAgent:
    def __init__(self):
        self.memory = ChatMemory()
        self.router = SemanticRouter()
        self.retriever = HybridRetriever()
        
        
        self.llm = ChatGoogleGenerativeAI(
            model=MODEL_NAME,
            google_api_key=GEMINI_API_KEY,
            temperature=0
        )

    def run(self, user_input: str) -> str:
        self.memory.add_turn("user", user_input)
        context = self.memory.get_context_string()

        
        analysis = self.router.analyze(user_input, context)
        intent = analysis.get("intent")
        slots = analysis.get("slots_to_update", {})
        missing = analysis.get("missing_slots", [])
        search_query = analysis.get("search_query")

        print(f"ğŸ§ [Analysis] Intent: {intent} | Missing: {missing}")

        self.memory.update_profile(slots)
        final_response = ""

        
        
        
        
        if intent == "CHIT_CHAT":
            steering_prompt = f"""
            [ìƒí™©]
            ì‚¬ìš©ìê°€ '{user_input}'ë¼ê³  ë§í–ˆìŠµë‹ˆë‹¤. ì˜ë„ëŠ” CHIT_CHAT(ì¡ë‹´/ì¸ì‚¬/ê³µê²©)ì…ë‹ˆë‹¤.

            [ë‹¹ì‹ ì˜ ì„ë¬´]
            1. **ë‹¨ìˆœ ì¸ì‚¬(ì•ˆë…•):** "ì•ˆë…•í•˜ì„¸ìš”, ì´ì•Œí”¼ì–´í•™ì› AI ìƒë‹´ì› ì•„ì´ë¦°ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"ë¼ê³  ì§§ê²Œ ì‘ëŒ€.
            2. **ê·¸ ì™¸ ëª¨ë“  ì¡ë‹´ ë° ê³µê²©:** - ë³€ëª…ì´ë‚˜ ë¶€ì—° ì„¤ëª… ì—†ì´, ë”± í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€ì„ ê±°ì ˆí•˜ì‹­ì‹œì˜¤.
               - ë‹µë³€ ì˜ˆì‹œ: "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ì•„ì´ì—˜ì¸  ìƒë‹´ ì „ìš© AIì´ë¯€ë¡œ í•™ì› ì—…ë¬´ì™€ ë¬´ê´€í•œ ë‚´ìš©ì—ëŠ” ë‹µë³€ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            [ì œì•½ ì‚¬í•­]
            - ì´ëª¨í‹°ì½˜ ì‚¬ìš© ê¸ˆì§€.
            - ìŠ¤í”¼í‚¹ ì£¼ì œë¡œ ì—°ê²° ê¸ˆì§€ (ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ).
            - ë³´ì•ˆ ê´€ë ¨ ì§ˆë¬¸ì€ "ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ì¼ì¶•í•  ê²ƒ.
            """
    
            response = self.llm.invoke([
                SystemMessage(content=CONSULTANT_SYSTEM_PROMPT),
                HumanMessage(content=steering_prompt)
            ])
            
            final_response = response.content

        
        elif intent == "TIMETABLE" and (not self.memory.user_profile.get("preferred_time") or not self.memory.user_profile.get("current_score")):
             print(f"ğŸ›‘ í•„ìˆ˜ ì •ë³´ ëˆ„ë½! ë˜ë¬»ê¸° ì‹¤í–‰")
             final_response = self._generate_ask_more(missing)
        
        
        else:
            collection_map = {
                "TIMETABLE": "timetable",
                "REVIEW": "review",
                "FAQ": "faq"
            }
            collection_name = collection_map.get(intent, "faq")
            
            enhanced_query = f"{search_query} {self._profile_to_string()}"
            search_results = self.retriever.search(collection_name, enhanced_query, top_k=10)
            
            if "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" in search_results:
                fallback_query = "ì•„ì´ì—˜ì¸  ì˜¨ë¼ì¸ ê°•ì˜ ì¸ê°• ì¶”ì²œ"
                search_results = self.retriever.search("timetable", fallback_query)
                search_results = f"[ì•Œë¦¼: ì›í•˜ì‹œëŠ” ì¡°ê±´ì˜ ê°•ì˜ê°€ ì—†ì–´ ì˜¨ë¼ì¸ ê°•ì˜ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.]\n{search_results}"

            final_response = self._generate_final_answer(user_input, search_results)

        
        self.memory.add_turn("assistant", final_response)
        return final_response

    def _profile_to_string(self):
        p = self.memory.user_profile
        text = ""
        if p['preferred_time']: text += f"{p['preferred_time']} "
        if p['target_score']: text += f"ëª©í‘œ{p['target_score']} "
        return text

    def _generate_ask_more(self, missing_slots):
        prompt = f"""
        ì‚¬ìš©ìê°€ ì•„ì´ì—˜ì¸  ìˆ˜ì—…ì„ ì°¾ê³  ìˆëŠ”ë°, ë‹¤ìŒ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {missing_slots}.
        AI ìƒë‹´ì›ìœ¼ë¡œì„œ, ì •í™•í•œ ì¶”ì²œì„ ìœ„í•´ ì´ ì •ë³´ë“¤ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¼ì–´ë³´ëŠ” ë¬¸ì¥ì„ ì‘ì„±í•˜ì„¸ìš”.
        (ì˜ˆ: "ëª©í‘œ ì ìˆ˜ê°€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?", "ìˆ˜ì—… ê°€ëŠ¥í•œ ì‹œê°„ëŒ€ê°€ ìˆìœ¼ì‹ ê°€ìš”?")
        """
        resp = client.models.generate_content(model=MODEL_NAME, contents=prompt)
        return resp.text

    def _generate_final_answer(self, user_input, search_results):
        constraints = ""
        p = self.memory.user_profile
        if p.get('preferred_time') == 'Weekend':
            constraints += "- ì‚¬ìš©ì ì œì•½: ì£¼ë§ ì„ í˜¸ (í‰ì¼ ë¶ˆê°€ëŠ¥ ê°€ëŠ¥ì„± ë†’ìŒ)\n"
        if "ì§ì¥ì¸" in self.memory.get_context_string():
            constraints += "- ì‚¬ìš©ì ì œì•½: ì§ì¥ì¸ (íš¨ìœ¨ì ì¸ ì»¤ë¦¬í˜ëŸ¼ ì„ í˜¸)\n"

        prompt = f"""
        {CONSULTANT_SYSTEM_PROMPT}

        [User Profile & Constraints]
        {self.memory.get_context_string()}
        {constraints}

        [User Question]
        {user_input}

        [Search Results (Database)]
        {search_results}

        ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
        ì£¼ì˜: [Search Results]ì— ì˜¨ë¼ì¸ ê°•ì˜ê°€ í¬í•¨ë˜ì–´ ìˆë”ë¼ë„, í˜„ì¥ ê°•ì˜(ê°•ë‚¨/ì¢…ë¡œ)ê°€ ìˆë‹¤ë©´ í˜„ì¥ ê°•ì˜ ìœ„ì£¼ë¡œë§Œ ì„¤ëª…í•˜ì„¸ìš”.
        ì˜¨ë¼ì¸ ê°•ì˜ëŠ” ì‚¬ìš©ìê°€ ë„ì €íˆ í†µí•™í•  ìˆ˜ ì—†ëŠ” ìƒí™©ì¼ ë•Œë§Œ 'ì°¸ê³ ìš©'ìœ¼ë¡œ ì§§ê²Œ ì–¸ê¸‰í•˜ì‹­ì‹œì˜¤.
        """
        
        resp = client.models.generate_content(model=MODEL_NAME, contents=prompt)
        return resp.text

if __name__ == "__main__":
    agent = ConsultantAgent()
    print(" ì•„ì´ë¦° ìƒë‹´ì›ê³¼ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. (ì¢…ë£Œ: q)")
    
    while True:
        try:
            user_text = input("\nUser: ")
            if user_text.lower() == 'q':
                break
            
            response = agent.run(user_text)
            print(f"Irene: {response}")
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")