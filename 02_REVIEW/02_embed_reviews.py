import os
import json
import time
from dotenv import load_dotenv
from google import genai
from google.genai import types




current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
env_path = os.path.join(parent_dir, '.env')

load_dotenv(dotenv_path=env_path)

api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError(f"API Key not found. Checked path: {env_path}")

client = genai.Client(api_key=api_key)

EMBEDDING_MODEL = 'models/text-embedding-004'


INPUT_FILE = os.path.join(current_dir, 'structured_reviews.json')
OUTPUT_FILE = os.path.join(current_dir, 'review_db_ready.json')

def create_embedding_payload(review_data):
    """
    êµ¬ì¡°í™”ëœ ìˆ˜ê°•í›„ê¸°ë¥¼ ë°›ì•„ ChromaDBìš© [ID, Vector, Metadata]ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    data = review_data
    
    
    if isinstance(data, list):
        data = data[0] if len(data) > 0 else None
    
    if not isinstance(data, dict):
        return None

    
    criteria = data.get('search_criteria', {})
    display = data.get('display_info', {})
    facts = data.get('fact_sheet', {})
    
    text_to_embed = f"""
    ìƒí™©(í˜ë¥´ì†Œë‚˜): {criteria.get('status', '')}
    ê°€ì¥ í° ê³ ë¯¼: {criteria.get('pain_point', '')}
    ìˆ˜ê°• ê°•ì¢Œ: {criteria.get('solution_course', '')}
    ë‹¬ì„± ê²°ê³¼: {criteria.get('outcome', '')}
    ê¸°ê°„: {facts.get('duration', '')}
    ì ìˆ˜ ë³€í™”: {facts.get('scores', '')}
    íƒœê·¸: {', '.join(display.get('tags', []))}
    """
    
    try:
        
        response = client.models.embed_content(
            model=EMBEDDING_MODEL,
            contents=text_to_embed,
            config=types.EmbedContentConfig(
                task_type="RETRIEVAL_DOCUMENT"
            )
        )
        vector = response.embeddings[0].values
        
    except Exception as e:
        print(f"âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ ({data['meta_data'].get('doc_id')}): {e}")
        return None
    
    
    
    
    metadata = {
        "category": "ìˆ˜ê°•í›„ê¸°",
        
        
        
        "url": data['meta_data'].get('source_url', ''), 
        
        
        "status": criteria.get('status', ''),
        
        
        "display_json": json.dumps(display, ensure_ascii=False),
        
        
        "fact_json": json.dumps(facts, ensure_ascii=False)
    }
    
    return {
        "id": data['meta_data']['doc_id'],
        "values": vector,
        "metadata": metadata,
        "document": text_to_embed 
    }

def main():
    
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            structured_data = json.load(f)
        print(f"ğŸ“‚ Loaded {len(structured_data)} reviews from {INPUT_FILE}")
    except FileNotFoundError:
        print(f"âŒ File not found: {INPUT_FILE}")
        print("Please run '01_preprocess_reviews.py' first.")
        return

    
    final_db_data = []
    
    print("ğŸš€ Starting embedding process for Reviews...")
    
    for idx, item in enumerate(structured_data):
        payload = create_embedding_payload(item)
        
        if payload:
            final_db_data.append(payload)
            print(f"   [{idx+1}/{len(structured_data)}] Vectorized: {payload['id']}")
        
        
        time.sleep(0.5)

    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_db_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ‰ Successfully saved {len(final_db_data)} vectors to:")
    print(f"ğŸ‘‰ {OUTPUT_FILE}")

if __name__ == "__main__":
    main()