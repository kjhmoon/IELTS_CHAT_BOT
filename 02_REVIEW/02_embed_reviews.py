import os
import json
import time
from dotenv import load_dotenv
from google import genai
from google.genai import types

# ------------------------------------------------------------------
# [ê²½ë¡œ ì„¤ì •]
# ------------------------------------------------------------------
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
env_path = os.path.join(parent_dir, '.env')

load_dotenv(dotenv_path=env_path)

api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError(f"API Key not found. Checked path: {env_path}")

client = genai.Client(api_key=api_key)

EMBEDDING_MODEL = 'models/text-embedding-004'

# ì…ì¶œë ¥ íŒŒì¼
INPUT_FILE = os.path.join(current_dir, 'structured_reviews.json')
OUTPUT_FILE = os.path.join(current_dir, 'review_db_ready.json')

def create_embedding_payload(review_data):
    """
    êµ¬ì¡°í™”ëœ ìˆ˜ê°•í›„ê¸°ë¥¼ ë°›ì•„ ChromaDBìš© [ID, Vector, Metadata]ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    data = review_data
    
    # ë¦¬ìŠ¤íŠ¸ í¬ì¥ ë²—ê¸°ê¸°
    if isinstance(data, list):
        data = data[0] if len(data) > 0 else None
    
    if not isinstance(data, dict):
        return None

    # 1. ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ìƒì„± (Serialize)
    criteria = data.get('search_criteria', {})
    display = data.get('display_info', {})
    facts = data.get('fact_sheet', {})
    
    text_to_embed = f"""
    ìƒí™©(í˜ë¥´ì†Œë‚˜): {criteria.get('status', '')}
    ê°€ì¥ í° ê³ ë¯¼: {criteria.get('pain_point', '')}
    ìˆ˜ê°• ê°•ì¢Œ: {criteria.get('solution_course', '')}
    ë‹¬ì„± ê²°ê³¼: {criteria.get('outcome', '')}
    ê¸°ê°„: {facts.get('duration', '')}
    ì ìˆ˜ ë³€í™”: {facts.get('scores', '')}
    íƒœê·¸: {', '.join(display.get('tags', []))}
    """
    
    try:
        # 2. ì„ë² ë”© ìƒì„±
        response = client.models.embed_content(
            model=EMBEDDING_MODEL,
            contents=text_to_embed,
            config=types.EmbedContentConfig(
                task_type="RETRIEVAL_DOCUMENT"
            )
        )
        vector = response.embeddings[0].values
        
    except Exception as e:
        print(f"âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ ({data['meta_data'].get('doc_id')}): {e}")
        return None
    
    # -----------------------------------------------------------
    # 3. ë©”íƒ€ë°ì´í„° êµ¬ì„± (ì—¬ê¸°ê°€ ì¤‘ìš”!)
    # -----------------------------------------------------------
    metadata = {
        "category": "ìˆ˜ê°•í›„ê¸°",
        
        # â˜…â˜…â˜… í•µì‹¬: ì›ë³¸ ë§í¬ ì €ì¥ â˜…â˜…â˜…
        # ë‚˜ì¤‘ì— ì±—ë´‡ì´ "ìì„¸í•œ ê±´ ì—¬ê¸°ì„œ ë³´ì„¸ìš”" í•˜ê³  ë§í¬ë¥¼ ì¤„ ìˆ˜ ìˆìŒ
        "url": data['meta_data'].get('source_url', ''), 
        
        # í•„í„°ë§ìš© ë°ì´í„°
        "status": criteria.get('status', ''),
        
        # UI í‘œì‹œìš© ë°ì´í„° (JSON ë¬¸ìì—´ë¡œ ì €ì¥)
        "display_json": json.dumps(display, ensure_ascii=False),
        
        # ë‹µë³€ ìƒì„± ì‹œ ì°¸ê³ í•  íŒ©íŠ¸
        "fact_json": json.dumps(facts, ensure_ascii=False)
    }
    
    return {
        "id": data['meta_data']['doc_id'],
        "values": vector,
        "metadata": metadata,
        "document": text_to_embed 
    }

def main():
    # 1. ë°ì´í„° ë¡œë“œ
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            structured_data = json.load(f)
        print(f"ğŸ“‚ Loaded {len(structured_data)} reviews from {INPUT_FILE}")
    except FileNotFoundError:
        print(f"âŒ File not found: {INPUT_FILE}")
        print("Please run '01_preprocess_reviews.py' first.")
        return

    # 2. ë²¡í„°í™”
    final_db_data = []
    
    print("ğŸš€ Starting embedding process for Reviews...")
    
    for idx, item in enumerate(structured_data):
        payload = create_embedding_payload(item)
        
        if payload:
            final_db_data.append(payload)
            print(f"   [{idx+1}/{len(structured_data)}] Vectorized: {payload['id']}")
        
        # ì„ë² ë”© APIëŠ” ì†ë„ ì œí•œì´ ë„ë„í•´ì„œ 0.5ì´ˆë©´ ì¶©ë¶„í•©ë‹ˆë‹¤.
        time.sleep(0.5)

    # 3. ì €ì¥
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_db_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ‰ Successfully saved {len(final_db_data)} vectors to:")
    print(f"ğŸ‘‰ {OUTPUT_FILE}")

if __name__ == "__main__":
    main()